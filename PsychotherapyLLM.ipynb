{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2TPC1zzgsb6",
        "outputId": "93736e26-12db-4b1e-9fc5-32934b30442f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 19 06:27:16 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q -U fsspec==2024.10.0"
      ],
      "metadata": {
        "id": "6QW06MdxPnYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW-VFqv3oS8j",
        "outputId": "bc900b9b-feb8-4230-c2b6-4f7916a598bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-3htdqdk5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-3htdqdk5\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 9613933b022ddbf085e2c593ed4ceea4c734179a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -q -U bitsandbytes==0.42.0\n",
        "!pip3 install -q -U peft==0.8.2\n",
        "!pip3 install -q -U trl\n",
        "!pip3 install -q -U accelerate==0.34.0\n",
        "!pip3 install -q -U datasets==2.21.0\n",
        "!pip3 install git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAjmoy-FPZj8",
        "outputId": "8683b304-7e90-449c-ec74-68fa44873a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==0.34.0\n",
            "aiohappyeyeballs==2.4.4\n",
            "aiohttp==3.11.10\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.19\n",
            "albumentations==1.4.20\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.20.0\n",
            "astropy==6.1.7\n",
            "astropy-iers-data==0.2024.12.16.0.35.48\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==24.3.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.16.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bigframes==1.29.0\n",
            "bigquery-magics==0.4.0\n",
            "bitsandbytes==0.42.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==0.7.11\n",
            "blosc2==2.7.1\n",
            "bokeh==3.6.2\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.43\n",
            "branca==0.8.1\n",
            "CacheControl==0.14.1\n",
            "cachetools==5.5.0\n",
            "catalogue==2.0.10\n",
            "certifi==2024.12.14\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.0\n",
            "chex==0.1.88\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpathlib==0.20.0\n",
            "cloudpickle==3.1.0\n",
            "cmake==3.31.2\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.0\n",
            "cycler==0.12.1\n",
            "cymem==2.0.10\n",
            "Cython==3.0.11\n",
            "dask==2024.10.0\n",
            "datascience==0.17.6\n",
            "datasets==2.21.0\n",
            "db-dtypes==1.3.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.15\n",
            "diffusers==0.31.0\n",
            "dill==0.3.8\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.0\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.4.3\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.0.4\n",
            "einops==0.8.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.11.0\n",
            "etuples==0.3.9\n",
            "eval_type_backport==0.2.0\n",
            "exceptiongroup==1.2.2\n",
            "fastai==2.7.18\n",
            "fastcore==1.7.27\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.16.1\n",
            "firebase-admin==6.6.0\n",
            "Flask==3.1.0\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.5\n",
            "folium==0.19.2\n",
            "fonttools==4.55.3\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.6.1\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.1\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.43\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.10\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.155.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.74.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.17.0\n",
            "google-cloud-bigquery-storage==2.27.0\n",
            "google-cloud-bigtable==2.27.0\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-datastore==2.20.2\n",
            "google-cloud-firestore==2.19.0\n",
            "google-cloud-functions==1.19.0\n",
            "google-cloud-iam==2.17.0\n",
            "google-cloud-language==2.16.0\n",
            "google-cloud-pubsub==2.27.1\n",
            "google-cloud-resource-manager==1.14.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.19.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-genai==0.2.2\n",
            "google-generativeai==0.8.3\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.66.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.13.1\n",
            "grpcio==1.68.1\n",
            "grpcio-status==1.62.3\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.4.1\n",
            "h5py==3.12.1\n",
            "holidays==0.63\n",
            "holoviews==1.20.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.27.0\n",
            "humanize==4.11.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "idna==3.10\n",
            "imageio==2.36.1\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.12.4\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.5.0\n",
            "importlib_resources==6.4.5\n",
            "imutils==0.5.4\n",
            "inflect==7.4.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.4\n",
            "intel-openmp==2025.0.4\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "jiter==0.8.2\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.5\n",
            "keras==3.5.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.7\n",
            "langchain==0.3.12\n",
            "langchain-core==0.3.25\n",
            "langchain-text-splitters==0.3.3\n",
            "langcodes==3.5.0\n",
            "langsmith==0.2.3\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.10.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.0\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.8.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.0.2\n",
            "mizani==0.13.1\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.3\n",
            "more-itertools==10.5.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.11\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.18.4\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.1\n",
            "nbconvert==7.16.4\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.10.2\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.6.4.1\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.6.85\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.6.0.74\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvidia-nvjitlink-cu12==12.6.85\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.10.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.57.4\n",
            "opencv-contrib-python==4.10.0.84\n",
            "opencv-python==4.10.0.84\n",
            "opencv-python-headless==4.10.0.84\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.29.0\n",
            "opentelemetry-sdk==1.29.0\n",
            "opentelemetry-semantic-conventions==0.50b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.13.1\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.12\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.25.0\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.5.4\n",
            "param==2.2.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.8\n",
            "peft==0.8.2\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.0.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.4\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.9.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.12.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.48\n",
            "propcache==0.2.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.25.0\n",
            "protobuf==4.25.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==17.0.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.3\n",
            "pydantic_core==2.27.1\n",
            "pydata-google-auth==1.9.0\n",
            "pydot==3.0.3\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.16.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.10.0\n",
            "pylibraft-cu12==24.10.0\n",
            "pymc==5.19.1\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.4.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.0\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.3\n",
            "pytensor==2.26.4\n",
            "pytest==8.3.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.9.1\n",
            "pytz==2024.2\n",
            "pyviz_comms==3.0.3\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==1.3.1\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==24.10.0\n",
            "rpds-py==0.22.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.5\n",
            "scikit-image==0.25.0\n",
            "scikit-learn==1.6.0\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.3.1\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.19.2\n",
            "setproctitle==1.3.4\n",
            "shap==0.46.0\n",
            "shapely==2.0.6\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.6\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.0.5\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.36\n",
            "sqlglot==25.1.0\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.0\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "StrEnum==0.4.15\n",
            "stringzilla==3.11.1\n",
            "sympy==1.13.1\n",
            "tables==3.10.1\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.17.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.17.1\n",
            "tensorflow-datasets==4.9.7\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.24.0\n",
            "tensorstore==0.1.71\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.17.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.12.12\n",
            "timm==1.0.12\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.21.0\n",
            "toml==0.10.2\n",
            "tomli==2.2.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121_full/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "tornado==6.3.3\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers @ git+https://github.com/huggingface/transformers.git@9613933b022ddbf085e2c593ed4ceea4c734179a\n",
            "trl==0.13.0\n",
            "tweepy==4.14.0\n",
            "typeguard==4.4.1\n",
            "typer==0.15.1\n",
            "types-pytz==2024.2.0.20241003\n",
            "types-setuptools==75.6.0.20241126\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.2\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.2.3\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.19.1\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==14.1\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.0\n",
            "xarray==2024.11.0\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.3\n",
            "xlrd==2.0.1\n",
            "xxhash==3.5.0\n",
            "xyzservices==2024.9.0\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.50\n",
            "zipp==3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "009ed911707d4dab87aa8813838359e2",
            "8d2255d940a04ffabc5714d8513df875",
            "0ba30fd5e13a445b9385dd796e498f95",
            "170b899e65104befbbb73e80425a5355",
            "d869a50649b84346944baf94871c57c1",
            "e76a42bb16234fce8022da8221c87a1b",
            "bb414d46c7b54f9fab19ee8b4187e33b",
            "6b7d8f6b06ea41a08bcfaca68342e618",
            "719e075277a0437dbe4afb76e002a3b1",
            "e354dc912d2a40b38ad4ff080a03f8cd",
            "b97ccad85bef47ae960a8597cc3a3c7b",
            "902ddde2733645a5accce538a5bfd537",
            "a55a5ec452744eb792801b7afc071f16",
            "48a6e034627c4aadb0943bbab7c0e2a8",
            "b7095c7d262d4ac49ec2f01e12c42907",
            "f666b8347568431d8c2cd756ffbb4dc1",
            "7fcbde0bbcb747cb9b8b45b99ea0f7f8",
            "86e549891e2546559bdb0904bb6aec01",
            "d3a139998e6243de88082fff3e9b7f6e",
            "5800f9607b764900be5362931c711e3a"
          ]
        },
        "id": "nvXpq76fooja",
        "outputId": "5723930b-1a8c-4615-94fe-6961636521df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "009ed911707d4dab87aa8813838359e2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5acd7712723344c18782593e022af0a9",
            "146f0f60824b41148e975782f94c0ef8",
            "e761d9a7e5c94448a6268c536f1f5720",
            "ea3c4577ddf44b8e8ec1801b4609fabb",
            "53eb2a6048e34e309b6aa5045f8c678c",
            "e8bcffab750941bc92d08d890bcf9e1e",
            "05779b17754d4c1f8504e87fe00bd1ab",
            "07f397799c2744feb1c6a568e9be75e6",
            "2200e9cff1454dd1a3c5ebebb9d0a852",
            "90cf8f7ae8c342848e67fd25df39186c",
            "4e50c37635b244b1aef6be6325fe9e05"
          ]
        },
        "id": "So6aHtcvo81H",
        "outputId": "fa0be7a7-3912-46ed-d029-739cd72e3a48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5acd7712723344c18782593e022af0a9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, use_cache=False, device_map={\"\":0})\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "NANulNWCPgHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UvXJz86qp12U",
        "outputId": "f3c9bd9e-b0c2-4d35-ece9-1c54d6db5ea3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-48-799d17d72845>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-799d17d72845>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <bos><start_of_turn>user\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "<bos><start_of_turn>user\n",
        "what are mental health issues<end_of_turn>\n",
        "<start_of_turn>model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6r3Kx_suTdR"
      },
      "outputs": [],
      "source": [
        "def get_completion(query: str, model, tokenizer) -> str:\n",
        "    device = \"cuda:0\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    <start_of_turn>user\n",
        "    Instruction for task completion is given below.\n",
        "    {query}\n",
        "    <end_of_turn>\\n<start_of_turn>model\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = prompt_template.format(query=query)\n",
        "    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "    generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_oNR2z2wmVo",
        "outputId": "ef4394c2-6dda-4bf6-aa7c-bcf8bb50b6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    user\n",
            "    Instruction for task completion is given below.\n",
            "    what are mental health issues?\n",
            "    \n",
            "model\n",
            "     Sure, here's a brief overview of what mental health issues are:\n",
            "\n",
            "Mental health issues, also known as mental disorders or mental health conditions, are conditions that affect a person's thoughts, feelings, behaviors, and overall well-being. They can manifest in various ways, including:\n",
            "\n",
            "- Feeling sad, anxious, or stressed\n",
            "- Experiencing negative thoughts or feelings\n",
            "- Having difficulty regulating emotions\n",
            "- Having difficulty making decisions\n",
            "- Having difficulty socializing with others\n",
            "- Engaging in self\n"
          ]
        }
      ],
      "source": [
        "result = get_completion(query=\"what are mental health issues?\", model=model, tokenizer=tokenizer)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh3V6lACwvJ8",
        "outputId": "323d1243-eb6d-4151-81a5-f64fc302fe24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 16084\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "ds1 = load_dataset(\"ShenLab/MentalChat16K\")\n",
        "ds1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds2 = load_dataset(\"fadodr/mental_health_therapy\")\n",
        "ds2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkOaC3R0CNiJ",
        "outputId": "fd4f98cd-c463-4a24-ce6c-628bb1465643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 8580\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 3678\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "dataset = concatenate_datasets([ds1['train'], ds2['train'], ds2['test']])"
      ],
      "metadata": {
        "id": "Q-FjBs-EK6fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gROKEhFWLzZp",
        "outputId": "51195f1f-1bf4-48ec-d179-89550647ff6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output'],\n",
              "    num_rows: 28342\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vmqODjs1J62"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(data_point):\n",
        "    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer\n",
        "\n",
        "    :param data_point: dict: Data point\n",
        "    :return: dict: tokenzed prompt\n",
        "    \"\"\"\n",
        "    prefix_text = 'Below is an instruction that describes a task. Write a response that ' \\\n",
        "               'appropriately completes the request.\\n\\n'\n",
        "\n",
        "    if data_point['input']:\n",
        "        text = f\"\"\"<start_of_turn>user {prefix_text} {data_point[\"instruction\"]} here are the inputs {data_point[\"input\"]} <end_of_turn>\\n<start_of_turn>model{data_point[\"output\"]} <end_of_turn>\"\"\"\n",
        "\n",
        "    else:\n",
        "        text = f\"\"\"<start_of_turn>user {prefix_text} {data_point[\"instruction\"]} <end_of_turn>\\n<start_of_turn>model{data_point[\"output\"]} <end_of_turn>\"\"\"\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text_column_train = [generate_prompt(data_point) for data_point in dataset['train']]\n",
        "#text_column_test = [generate_prompt(data_point) for data_point in dataset['test']]"
      ],
      "metadata": {
        "id": "9YMynRTUJc6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset['train'] = dataset['train'].add_column(\"prompt\", text_column_train)\n",
        "#dataset['test'] = dataset['test'].add_column(\"prompt\", text_column_test)"
      ],
      "metadata": {
        "id": "lLMr0E9_JlN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
        "dataset = dataset.add_column(\"prompt\", text_column)"
      ],
      "metadata": {
        "id": "G7sE1kJyP-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = concatenate_datasets([dataset['train'], dataset['test']])"
      ],
      "metadata": {
        "id": "JU_qEQdIJuWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwuEhtOO1-8A",
        "outputId": "0aaedb30-f30e-4c20-e15f-1818a93b61ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output', 'prompt'],\n",
              "    num_rows: 28342\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "dataset = dataset.shuffle(seed=3241)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vacHKncG2BGp"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTUCvUEz3Uw7",
        "outputId": "50f0f6f3-1345-45c6-e45d-68c3e47e5a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output', 'prompt'],\n",
            "    num_rows: 5669\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt9tqPiq3dJY",
        "outputId": "9c221daf-0885-467a-b24c-30ad03049bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output', 'prompt'],\n",
            "    num_rows: 22673\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKImzMXj3pv_"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vv65RjI3saQ",
        "outputId": "3c36bb2d-5f57-4ec0-f8d2-2a632aee98c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GemmaForCausalLM(\n",
            "  (model): GemmaModel(\n",
            "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-17): 18 x GemmaDecoderLayer(\n",
            "        (self_attn): GemmaAttention(\n",
            "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): GemmaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
            "          (act_fn): GELUActivation()\n",
            "        )\n",
            "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "    (rotary_emb): GemmaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_func(example):\n",
        "    text = f\"Advice: {example['output'][0]}\\nProblem: {example['input'][0]}<eos>\"\n",
        "    return [text]\n",
        "formatting_func(dataset[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAgOcA_hQ6hd",
        "outputId": "aeb189b3-2491-4a42-d4da-3f880bf9891c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Advice: I hear you're going through a difficult time and experiencing deep sadness. It can be really tough when things that used to bring you joy no longer do, and it's understandable that this situation is affecting your ability to concentrate and find enjoyment in things.\\n\\nFirstly, I want to acknowledge your courage for seeking help through counseling. It's a positive step towards understanding your depression better and finding ways to lift your spirits. In therapy, you can explore the underlying causes of your sadness and learn coping strategies to manage it.\\n\\nOne approach that may be beneficial is cognitive-behavioral therapy (CBT). CBT focuses on identifying negative thought patterns and challenging them with more balanced and realistic thoughts. Through this approach, you can uncover any unhelpful beliefs contributing to your depression and work towards developing healthier ones.\\n\\nAnother helpful technique is building a strong support system around you. Surrounding yourself with loved ones who are empathetic and understanding can provide emotional support during this challenging period. Additionally, consider reaching out to local support groups or online communities where you can connect with others who may be facing similar struggles.\\n\\nTaking care of your physical health is also important in managing depression. Engaging in regular exercise, practicing good sleep hygiene, and maintaining a healthy diet can all contribute positively to your overall well-being.\\n\\nIt's worth mentioning that while these suggestions can be important steps towards feeling better, recovery from depression is a process unique to each individual, and progress may take time. Remember to be patient and kind to yourself throughout this journey.\\n\\nIf at any point you feel overwhelmed or experience thoughts of self-harm or suicide, please reach out to a crisis hotline or emergency services immediately. They are there to provide immediate assistance and ensure your safety.\\n\\nI believe that by working together in therapy, exploring different strategies, and being proactive in taking care of your mental and physical health, there is hope for improvement and finding joy once again. You deserve to feel better, and through this journey, remember that you're not alone.\\nProblem: Hi, thank you for your time. Lately, I've been experiencing deep sadness and a loss of interest in activities I once loved. I often find myself crying for no apparent reason. This cloud hanging over me makes it hard to concentrate or find enjoyment in anything. Through counseling, I hope to better understand my depression and find ways to lift my spirits.<eos>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-m-M6Fa3vEX"
      },
      "outputs": [],
      "source": [
        "import bitsandbytes as bnb\n",
        "def find_all_linear_names(model):\n",
        "  cls = bnb.nn.Linear4bit\n",
        "  lora_module_names = set()\n",
        "  for name, module in model.named_modules():\n",
        "    if isinstance(module, cls):\n",
        "      names = name.split('.')\n",
        "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "    if 'lm_head' in lora_module_names:\n",
        "      lora_module_names.remove('lm_head')\n",
        "  return list(lora_module_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axjWOzT-3w9T",
        "outputId": "fecf6579-855f-44eb-91c3-e40ce236b873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gate_proj', 'o_proj', 'down_proj', 'up_proj', 'v_proj', 'k_proj', 'q_proj']\n"
          ]
        }
      ],
      "source": [
        "modules = find_all_linear_names(model)\n",
        "print(modules)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItzI4n2e3zgJ"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=32,\n",
        "    #target_modules=modules,\n",
        "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LBFZr9T32b_",
        "outputId": "76a9fc27-2e49-4c5c-f922-a8b7e1f543ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable: 78446592 | total: 2584619008 | Percentage: 3.0351%\n"
          ]
        }
      ],
      "source": [
        "trainable, total = model.get_nb_trainable_parameters()\n",
        "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=3,\n",
        "        max_steps=15,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\"\n",
        "    ),\n",
        "    peft_config=lora_config,\n",
        "    formatting_func=formatting_func,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "whvBIS6vRY2v",
        "outputId": "29d19d46-1336-4550-8d92-c661f2aa9edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GemmaModel.forward() got an unexpected keyword argument 'num_items_in_batch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-a6224b0a188b>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mformatting_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                     )\n\u001b[1;32m   2523\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3669\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3671\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3721\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3723\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3724\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             return self.base_model(\n\u001b[0m\u001b[1;32m   1084\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    839\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GemmaModel.forward() got an unexpected keyword argument 'num_items_in_batch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Input: I feel like im not meant to be here. Like nobody would care if I existed or not. Due to that, I've been feeling like ending my life.\"\n",
        "device = \"cuda:0\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "dl4XLrhUp5Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**inputs, max_new_tokens=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiBI7RrISKAR",
        "outputId": "e4be2c14-74a6-4045-8ee4-4bcc0ef8ffba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf88QktMSWw6",
        "outputId": "f434ebad-8a0a-453c-97fd-7738eabd198a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I feel like im not meant to be here. Like nobody would care if I existed or not. Due to that, I've been feeling like ending my life.The input is very concerning and I would like to offer some support. It's important to know that you are not alone and that there are people who care about you. Please reach out for help if you are feeling suicidal. There are many resources available to you, including hotlines, mental health professionals, and support groups. Please don't hesitate to reach out for help.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"gemma_psychology_saved\")"
      ],
      "metadata": {
        "id": "Bq_dLZb1W4PC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009ed911707d4dab87aa8813838359e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_bb414d46c7b54f9fab19ee8b4187e33b"
          }
        },
        "8d2255d940a04ffabc5714d8513df875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7d8f6b06ea41a08bcfaca68342e618",
            "placeholder": "​",
            "style": "IPY_MODEL_719e075277a0437dbe4afb76e002a3b1",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0ba30fd5e13a445b9385dd796e498f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e354dc912d2a40b38ad4ff080a03f8cd",
            "placeholder": "​",
            "style": "IPY_MODEL_b97ccad85bef47ae960a8597cc3a3c7b",
            "value": ""
          }
        },
        "170b899e65104befbbb73e80425a5355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_902ddde2733645a5accce538a5bfd537",
            "style": "IPY_MODEL_a55a5ec452744eb792801b7afc071f16",
            "value": true
          }
        },
        "d869a50649b84346944baf94871c57c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_48a6e034627c4aadb0943bbab7c0e2a8",
            "style": "IPY_MODEL_b7095c7d262d4ac49ec2f01e12c42907",
            "tooltip": ""
          }
        },
        "e76a42bb16234fce8022da8221c87a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f666b8347568431d8c2cd756ffbb4dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_7fcbde0bbcb747cb9b8b45b99ea0f7f8",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "bb414d46c7b54f9fab19ee8b4187e33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6b7d8f6b06ea41a08bcfaca68342e618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719e075277a0437dbe4afb76e002a3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e354dc912d2a40b38ad4ff080a03f8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97ccad85bef47ae960a8597cc3a3c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902ddde2733645a5accce538a5bfd537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55a5ec452744eb792801b7afc071f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a6e034627c4aadb0943bbab7c0e2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7095c7d262d4ac49ec2f01e12c42907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f666b8347568431d8c2cd756ffbb4dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcbde0bbcb747cb9b8b45b99ea0f7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e549891e2546559bdb0904bb6aec01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a139998e6243de88082fff3e9b7f6e",
            "placeholder": "​",
            "style": "IPY_MODEL_5800f9607b764900be5362931c711e3a",
            "value": "Connecting..."
          }
        },
        "d3a139998e6243de88082fff3e9b7f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5800f9607b764900be5362931c711e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5acd7712723344c18782593e022af0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_146f0f60824b41148e975782f94c0ef8",
              "IPY_MODEL_e761d9a7e5c94448a6268c536f1f5720",
              "IPY_MODEL_ea3c4577ddf44b8e8ec1801b4609fabb"
            ],
            "layout": "IPY_MODEL_53eb2a6048e34e309b6aa5045f8c678c"
          }
        },
        "146f0f60824b41148e975782f94c0ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bcffab750941bc92d08d890bcf9e1e",
            "placeholder": "​",
            "style": "IPY_MODEL_05779b17754d4c1f8504e87fe00bd1ab",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e761d9a7e5c94448a6268c536f1f5720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f397799c2744feb1c6a568e9be75e6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2200e9cff1454dd1a3c5ebebb9d0a852",
            "value": 2
          }
        },
        "ea3c4577ddf44b8e8ec1801b4609fabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90cf8f7ae8c342848e67fd25df39186c",
            "placeholder": "​",
            "style": "IPY_MODEL_4e50c37635b244b1aef6be6325fe9e05",
            "value": " 2/2 [00:22&lt;00:00,  9.56s/it]"
          }
        },
        "53eb2a6048e34e309b6aa5045f8c678c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8bcffab750941bc92d08d890bcf9e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05779b17754d4c1f8504e87fe00bd1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07f397799c2744feb1c6a568e9be75e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2200e9cff1454dd1a3c5ebebb9d0a852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90cf8f7ae8c342848e67fd25df39186c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e50c37635b244b1aef6be6325fe9e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}